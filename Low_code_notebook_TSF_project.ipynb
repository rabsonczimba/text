{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Ho8VGKDu3S"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "W_Ho8VGKDu3S"
    },
    {
      "cell_type": "markdown",
      "id": "dfea7d86",
      "metadata": {
        "id": "dfea7d86"
      },
      "source": [
        "For this particular assignment, the data of different types of wine sales in the 20th century is to be analysed. Both of these data are from the same company but of different wines. As an analyst in the ABC Estate Wines, you are tasked to analyse and forecast Wine Sales in the 20th century."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286ede49"
      },
      "source": [
        "## **Please read the instructions carefully before starting the project.** \n",
        "\n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned. \n",
        "* Blanks '_______' are provided in the notebook that \n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space. \n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"
      ],
      "id": "286ede49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5QE-n57qf9"
      },
      "source": [
        "## Importing necessary libraries"
      ],
      "id": "9d5QE-n57qf9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2078eaed",
      "metadata": {
        "id": "2078eaed"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA as ar\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels as st\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import itertools\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "#import plotly.offline as py\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from pylab import rcParams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ],
      "id": "xxhpZv9y-qTw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e76bb595",
      "metadata": {
        "id": "e76bb595"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('_______') ##  Fill the blank to read the data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Overview"
      ],
      "metadata": {
        "id": "_ruS1OQwB_fX"
      },
      "id": "_ruS1OQwB_fX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlzqMR1K-qTz"
      },
      "source": [
        "### Displaying the first few rows of the dataset"
      ],
      "id": "qlzqMR1K-qTz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9117e987",
      "metadata": {
        "id": "9117e987"
      },
      "outputs": [],
      "source": [
        "df.'_______' ##  Complete the code to view top 5 rows of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQi5ygTC-qT1"
      },
      "source": [
        "### Checking the shape of the dataset"
      ],
      "id": "KQi5ygTC-qT1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kpbqHeZ7qgA"
      },
      "outputs": [],
      "source": [
        "# checking shape of the data\n",
        "print(f\"There are {df.shape[___]} rows and {df.shape[__]} columns.\") # Complete the code to view dimensions of the data"
      ],
      "id": "-kpbqHeZ7qgA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TcqcxbK-qT3"
      },
      "source": [
        "### Checking the data types of the columns for the dataset"
      ],
      "id": "5TcqcxbK-qT3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-9OPXv07qgC"
      },
      "outputs": [],
      "source": [
        "# checking column datatypes and number of non-null values\n",
        "df.info()"
      ],
      "id": "W-9OPXv07qgC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "- `YearMonth` is *object* type columns and Sparkling is *numerical* type column."
      ],
      "metadata": {
        "id": "EYhixOP0K_KJ"
      },
      "id": "EYhixOP0K_KJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Pre processing "
      ],
      "metadata": {
        "id": "GUSrEdHZqHbl"
      },
      "id": "GUSrEdHZqHbl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53220ef",
      "metadata": {
        "id": "a53220ef"
      },
      "outputs": [],
      "source": [
        "Time_Stamp = pd.date_range(start='1980-01-01',periods=len(df),freq='M')\n",
        "Time_Stamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab39f7b",
      "metadata": {
        "id": "5ab39f7b"
      },
      "outputs": [],
      "source": [
        "df['Time_Stamp'] = Time_Stamp\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb9a9fb",
      "metadata": {
        "id": "ebb9a9fb"
      },
      "outputs": [],
      "source": [
        "df.set_index(keys='Time_Stamp',inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04aa28f",
      "metadata": {
        "id": "c04aa28f"
      },
      "outputs": [],
      "source": [
        "df.drop(['____'],axis=1,inplace=True) #Complete the code to drop the column 'YearMonth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069cd502",
      "metadata": {
        "id": "069cd502"
      },
      "outputs": [],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNr4bWoM-qT5"
      },
      "source": [
        "### Checking for missing values"
      ],
      "id": "xNr4bWoM-qT5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5nw3F87qgJ"
      },
      "source": [
        "**Before we start exploring the data further, let's quickly check the missingness in the data.**"
      ],
      "id": "og5nw3F87qgJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7vM9KqH7qgJ"
      },
      "outputs": [],
      "source": [
        "df.'_____' # Complete the code to check the presence of missing values "
      ],
      "id": "I7vM9KqH7qgJ"
    },
    {
      "cell_type": "code",
      "source": [
        "df.'_______' ##  Complete the code to view top 5 rows of the data"
      ],
      "metadata": {
        "id": "LBpaZ2mGMfW4"
      },
      "id": "LBpaZ2mGMfW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUJ_B5KxhU3D"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n"
      ],
      "id": "kUJ_B5KxhU3D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bivariate Analysis"
      ],
      "metadata": {
        "id": "HdlR3wVEMyfW"
      },
      "id": "HdlR3wVEMyfW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `Timestamp` vs `Sparkling`"
      ],
      "metadata": {
        "id": "DfHslI2IMcAo"
      },
      "id": "DfHslI2IMcAo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f89d57",
      "metadata": {
        "id": "d2f89d57"
      },
      "outputs": [],
      "source": [
        "## let's plot the sparkling vs timestamp \n",
        "plt.plot(df);\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9f178de",
      "metadata": {
        "id": "c9f178de"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x = df.index.year,y = df['_____']) # Complete the code to check the relationship between the 'Sparkling' column and 'Time_Stamp' \n",
        "plt.grid(); "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ae0c65",
      "metadata": {
        "id": "e5ae0c65"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x = df.index.month_name(),y = df['____']) # Complete the code to check the relationship between the 'Sparkling' column and 'Time_Stamp' \n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decomposition "
      ],
      "metadata": {
        "id": "v8bdGtOaqYtW"
      },
      "id": "v8bdGtOaqYtW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a842122a",
      "metadata": {
        "id": "a842122a"
      },
      "outputs": [],
      "source": [
        "decomposition = seasonal_decompose(df,model='______') ##Complete the code to check additive Decomposition\n",
        "decomposition.plot(); "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac8d7d9",
      "metadata": {
        "id": "7ac8d7d9"
      },
      "outputs": [],
      "source": [
        "trend = decomposition.trend\n",
        "seasonality = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "print('Trend','\\n',trend.head(12),'\\n')\n",
        "print('Seasonality','\\n',seasonality.head(12),'\\n')\n",
        "print('Residual','\\n',residual.head(12),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for additive assumptions"
      ],
      "metadata": {
        "id": "L8hu0DaYWNoC"
      },
      "id": "L8hu0DaYWNoC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dcfe925",
      "metadata": {
        "id": "0dcfe925"
      },
      "outputs": [],
      "source": [
        "residual.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb093bf",
      "metadata": {
        "id": "fbb093bf"
      },
      "outputs": [],
      "source": [
        "##Normality Distribution of Resid\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "sns.distplot(residual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b97f26e",
      "metadata": {
        "id": "3b97f26e"
      },
      "outputs": [],
      "source": [
        "shapiro(residual.dropna())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiplicative Decomposition\n"
      ],
      "metadata": {
        "id": "lCBmm5L-rA0o"
      },
      "id": "lCBmm5L-rA0o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce09b27",
      "metadata": {
        "id": "5ce09b27"
      },
      "outputs": [],
      "source": [
        "#Multiplicative Decomposition\n",
        "decomposition = seasonal_decompose(df,model='_____') # complete the code to multiplicative decomposition\n",
        "decomposition.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e869dc3",
      "metadata": {
        "id": "1e869dc3"
      },
      "outputs": [],
      "source": [
        "trend = decomposition.trend\n",
        "seasonality = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "print('Trend','\\n',trend.head(12),'\\n')\n",
        "print('Seasonality','\\n',seasonality.head(12),'\\n')\n",
        "print('Residual','\\n',residual.head(12),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for Multiplicative assumptions"
      ],
      "metadata": {
        "id": "P2TcixowVlSL"
      },
      "id": "P2TcixowVlSL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b890328",
      "metadata": {
        "id": "3b890328"
      },
      "outputs": [],
      "source": [
        "residual = decomposition.resid\n",
        "residual.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a162899d",
      "metadata": {
        "id": "a162899d"
      },
      "outputs": [],
      "source": [
        "sns.distplot(residual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c1061b",
      "metadata": {
        "id": "82c1061b"
      },
      "outputs": [],
      "source": [
        "shapiro(residual.dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653d80b0",
      "metadata": {
        "id": "653d80b0"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for Modeling\n"
      ],
      "metadata": {
        "id": "but7oI7m2vvY"
      },
      "id": "but7oI7m2vvY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716c783b",
      "metadata": {
        "id": "716c783b"
      },
      "outputs": [],
      "source": [
        "df.index.year.'_____'  ## Complete the code to check the unique values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87521bf1",
      "metadata": {
        "id": "87521bf1"
      },
      "outputs": [],
      "source": [
        "### Complete the code to take all data till the year 1991 in the train set and everything after that in the test set\n",
        "df_train = df[df.index <= \"_____\"] \n",
        "df_test = df[df.index > \"_____\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8df1e4",
      "metadata": {
        "id": "3f8df1e4"
      },
      "outputs": [],
      "source": [
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check the train dataset "
      ],
      "metadata": {
        "id": "hsnaQaXxXVNC"
      },
      "id": "hsnaQaXxXVNC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22027b9f",
      "metadata": {
        "id": "22027b9f"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check the test dataset "
      ],
      "metadata": {
        "id": "p8L4YPHcXdzh"
      },
      "id": "p8L4YPHcXdzh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe685f2",
      "metadata": {
        "id": "cfe685f2"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building "
      ],
      "metadata": {
        "id": "BORpLf603HRr"
      },
      "id": "BORpLf603HRr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression Model"
      ],
      "metadata": {
        "id": "FnwnQeVMYJjY"
      },
      "id": "FnwnQeVMYJjY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For this particular linear regression, we are going to regress the 'Sparkling' variable against the order of the occurrence. \n",
        "- For this we need to modify our training data before fitting it into a linear regression."
      ],
      "metadata": {
        "id": "CQ7coe3PYXxW"
      },
      "id": "CQ7coe3PYXxW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28723a61",
      "metadata": {
        "id": "28723a61"
      },
      "outputs": [],
      "source": [
        "train_time = [i+1 for i in range(len(df_train))]\n",
        "test_time = [i+133 for i in range(len(df_test))]\n",
        "print('Training Time instance','\\n',train_time)\n",
        "print('Test Time instance','\\n',test_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80986205",
      "metadata": {
        "id": "80986205"
      },
      "outputs": [],
      "source": [
        "LinearRegression_train = df_train.copy()\n",
        "LinearRegression_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a30c6aa8",
      "metadata": {
        "id": "a30c6aa8"
      },
      "outputs": [],
      "source": [
        "LinearRegression_train['time'] = train_time\n",
        "LinearRegression_test['time'] = test_time\n",
        "\n",
        "print('First few rows of Training Data','\\n',LinearRegression_train.head(),'\\n')\n",
        "print('Last few rows of Training Data','\\n',LinearRegression_train.tail(),'\\n')\n",
        "print('First few rows of Test Data','\\n',LinearRegression_test.head(),'\\n')\n",
        "print('Last few rows of Test Data','\\n',LinearRegression_test.tail(),'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0763d647",
      "metadata": {
        "id": "0763d647"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5cb8a7",
      "metadata": {
        "id": "af5cb8a7"
      },
      "outputs": [],
      "source": [
        "LinearRegression_train['Sparkling'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebc7651",
      "metadata": {
        "id": "3ebc7651"
      },
      "outputs": [],
      "source": [
        "lr.fit(LinearRegression_train[['time']],LinearRegression_train['Sparkling'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f862db4f",
      "metadata": {
        "id": "f862db4f"
      },
      "outputs": [],
      "source": [
        "test_prediction_model = lr.predict(LinearRegression_test[['time']])\n",
        "LinearRegression_test['RegOnTime']=test_prediction_model\n",
        "\n",
        "plt.figure(figsize=(15,12))\n",
        "plt.plot(df_train['Sparkling'],label='Train')\n",
        "plt.plot(df_test['Sparkling'],label='Test')\n",
        "plt.plot(LinearRegression_test['RegOnTime'],label='Regression On Time_Test Data')\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7102465a",
      "metadata": {
        "id": "7102465a"
      },
      "outputs": [],
      "source": [
        "rmse_model_test= metrics.mean_squared_error(df_test['Sparkling'],test_prediction_model,squared=False)\n",
        "print(\"For RegressionOnTime forecast on the Test Data,  RMSE is %3.3f\" %(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27662fc2",
      "metadata": {
        "scrolled": true,
        "id": "27662fc2"
      },
      "outputs": [],
      "source": [
        "resultsDf = pd.DataFrame({'Test RMSE': [rmse_model_test]},index=['RegressionOnTime'])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Approach Model"
      ],
      "metadata": {
        "id": "_P3Jx09Ucg1x"
      },
      "id": "_P3Jx09Ucg1x"
    },
    {
      "cell_type": "markdown",
      "id": "68b8a758",
      "metadata": {
        "id": "68b8a758"
      },
      "source": [
        "For this particular naive model, we say that the prediction for tomorrow is the same as today and the prediction for day after tomorrow is tomorrow and since the prediction of tomorrow is same as today,therefore the prediction for day after tomorrow is also today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0307c6e",
      "metadata": {
        "id": "b0307c6e"
      },
      "outputs": [],
      "source": [
        "NaiveModel_train = '_____'.copy() # Complete the code to create a copy of the train datasets\n",
        "NaiveModel_test = '_____'.copy() # Complete the code to create a copy of the test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e875978",
      "metadata": {
        "id": "8e875978"
      },
      "outputs": [],
      "source": [
        "NaiveModel_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663e2a53",
      "metadata": {
        "id": "663e2a53"
      },
      "outputs": [],
      "source": [
        "NaiveModel_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78cffb9",
      "metadata": {
        "id": "f78cffb9"
      },
      "outputs": [],
      "source": [
        "NaiveModel_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cba3797",
      "metadata": {
        "id": "0cba3797"
      },
      "outputs": [],
      "source": [
        "NaiveModel_test['naive'] = np.asarray(df_train['Sparkling'])[len(np.asarray(df_train['Sparkling']))-1]\n",
        "NaiveModel_test['naive'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a32cdf7",
      "metadata": {
        "id": "8a32cdf7"
      },
      "outputs": [],
      "source": [
        "NaiveModel_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edf2c6b",
      "metadata": {
        "id": "4edf2c6b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "plt.plot(NaiveModel_train['Sparkling'],label='Train')\n",
        "plt.plot(df_test['Sparkling'],label='Test')\n",
        "plt.plot(NaiveModel_test['naive'], label='Naive Forecast on test data')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Naive Forecast')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a19359",
      "metadata": {
        "id": "e1a19359"
      },
      "outputs": [],
      "source": [
        "##MODEL EVAULATION\n",
        "rmse_model_test = metrics.mean_squared_error(df_test['Sparkling'],NaiveModel_test['naive'],squared=False)\n",
        "print(\"For Naive On Time Forecast on the Test Data, RMSE is %3.3f\" %(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3b18d2",
      "metadata": {
        "id": "bf3b18d2"
      },
      "outputs": [],
      "source": [
        "resultsDfN = pd.DataFrame({'Test RMSE': [rmse_model_test]}, index=['________']) # Complete the code to check the perfromance of the 'NaiveModel' \n",
        "resultsDf = pd.concat([resultsDf,resultsDfN])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Average Model "
      ],
      "metadata": {
        "id": "D42POulbfTks"
      },
      "id": "D42POulbfTks"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this particular simple average method, we will forecast by using the average of the training values."
      ],
      "metadata": {
        "id": "yKWXSW_LrpBQ"
      },
      "id": "yKWXSW_LrpBQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de0cf10",
      "metadata": {
        "id": "9de0cf10"
      },
      "outputs": [],
      "source": [
        "# Let's create the copy of the train and test dataset \n",
        "SimpleAverage_train = '_____'.copy() # Complete the code to create a copy of the train datasets\n",
        "SimpleAverage_test = '_____'.copy() # Complete the code to create a copy of the test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec26859",
      "metadata": {
        "id": "1ec26859"
      },
      "outputs": [],
      "source": [
        "SimpleAverage_test['mean forecast']= df_train['Sparkling'].mean()\n",
        "SimpleAverage_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583aec9c",
      "metadata": {
        "id": "583aec9c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,12))\n",
        "plt.plot(df_train['Sparkling'],label='Train')\n",
        "plt.plot(df_test['Sparkling'], label='Test')\n",
        "plt.plot(SimpleAverage_test['mean forecast'],label='Simple Average on Test Data')\n",
        "plt.legend(loc='best')\n",
        "plt.title(\"Simple Average Forecast\")\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdfb606",
      "metadata": {
        "id": "0bdfb606"
      },
      "outputs": [],
      "source": [
        "##MODEL EVAULATION\n",
        "rmse_model_test = metrics.mean_squared_error(df_test['Sparkling'],SimpleAverage_test['mean forecast'],squared=False)\n",
        "print(\"For Simple Average Forecast on Test Data, RMSE is %3.3f\"%(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f776177f",
      "metadata": {
        "id": "f776177f"
      },
      "outputs": [],
      "source": [
        "resultsDfSES = pd.DataFrame({'Test RMSE':  [rmse_model_test]},index=['_____']) # Complete the code to check the perfromance of the 'SimpleAverageModel' \n",
        "resultsDf = pd.concat([resultsDf,resultsDfSES])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162eb75",
      "metadata": {
        "id": "c162eb75"
      },
      "outputs": [],
      "source": [
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Exponential Smoothing Model "
      ],
      "metadata": {
        "id": "x7vtp9Jdfk0A"
      },
      "id": "x7vtp9Jdfk0A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e77d99",
      "metadata": {
        "id": "a2e77d99"
      },
      "outputs": [],
      "source": [
        "# Let's create the train and test dataset \n",
        "SES_train = '_____'.copy() # Complete the code to create a copy of the train datasets\n",
        "SES_test =  '_____'.copy() # Complete the code to create a copy of the test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e003bb73",
      "metadata": {
        "id": "e003bb73"
      },
      "outputs": [],
      "source": [
        "model_SES = SimpleExpSmoothing(SES_train['Sparkling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1771cedc",
      "metadata": {
        "id": "1771cedc"
      },
      "outputs": [],
      "source": [
        "model_SES_autofit = model_SES.fit(optimized=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a30b15",
      "metadata": {
        "id": "88a30b15"
      },
      "outputs": [],
      "source": [
        "model_SES_autofit.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2983b4",
      "metadata": {
        "id": "dc2983b4"
      },
      "outputs": [],
      "source": [
        "SES_test['predict'] = model_SES_autofit.forecast(steps=len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8a59c5",
      "metadata": {
        "id": "9b8a59c5"
      },
      "outputs": [],
      "source": [
        "SES_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4c1e4e",
      "metadata": {
        "scrolled": false,
        "id": "dc4c1e4e"
      },
      "outputs": [],
      "source": [
        "## Plotting on both the Training and Test data\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(SES_train['Sparkling'], label='Train')\n",
        "plt.plot(SES_test['Sparkling'], label='Test')\n",
        "\n",
        "plt.plot(SES_test['predict'], label='Alpha = 0.05 Simple Exponential Smoothing predictions on Test Set')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.title('Alpha = 0.05 Predictions');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Evaluation for  𝛼  = 0.05 : Simple Exponential Smoothing"
      ],
      "metadata": {
        "id": "H_3ju6TfxaXn"
      },
      "id": "H_3ju6TfxaXn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145f15ca",
      "metadata": {
        "id": "145f15ca"
      },
      "outputs": [],
      "source": [
        "rmse_model_test = metrics.mean_squared_error(SES_test['Sparkling'],SES_test['predict'],squared=False)\n",
        "print(\"For Alpha = 0.05 SES Model on Test Data,RMSE is %3.3f\" %(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba030b2",
      "metadata": {
        "id": "cba030b2"
      },
      "outputs": [],
      "source": [
        "resultsDf_1 = pd.DataFrame({'Test RMSE': [rmse_model_test]},index=['______'])   # Complete the code to check the perfromance of the 'Alpha = 0.05,SimpleExponentialSmoothing' \n",
        "resultsDf = pd.concat([resultsDf, resultsDf_1])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c30bad7",
      "metadata": {
        "id": "7c30bad7"
      },
      "source": [
        "#### Setting different alpha values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, the higher the alpha value more weightage is given to the more recent observation. That means, what happened recently will happen again.\n",
        "We will run a loop with different alpha values to understand which particular value works best for alpha on the test set."
      ],
      "metadata": {
        "id": "xX2Rxdo8fsOk"
      },
      "id": "xX2Rxdo8fsOk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will define an empty dataframe to store our values from the loop\n"
      ],
      "metadata": {
        "id": "4KUSJ9vgiZv5"
      },
      "id": "4KUSJ9vgiZv5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fccf2b",
      "metadata": {
        "id": "89fccf2b"
      },
      "outputs": [],
      "source": [
        "resultsDf_a = pd.DataFrame({'Alpha Values':[],'Train RMSE':[],'Test RMSE': []})\n",
        "resultsDf_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7223e7",
      "metadata": {
        "id": "ea7223e7"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(0.3,1,0.1):\n",
        "    model_SES_alpha_i = model_SES.fit(smoothing_level=i,optimized=False,use_brute=True)\n",
        "    SES_train['predict',i] = model_SES_alpha_i.fittedvalues\n",
        "    SES_test['predict',i] = model_SES_alpha_i.forecast(steps=55)\n",
        "    \n",
        "    rmse_model5_train_i = metrics.mean_squared_error(SES_train['Sparkling'],SES_train['predict',i],squared=False)\n",
        "    \n",
        "    rmse_model5_test_i = metrics.mean_squared_error(SES_test['Sparkling'],SES_test['predict',i],squared=False)\n",
        "    \n",
        "    resultsDf_a = resultsDf_a.append({'Alpha Values':i,'Train RMSE':rmse_model5_train_i \n",
        "                                      ,'Test RMSE':rmse_model5_test_i}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc04e16",
      "metadata": {
        "id": "5fc04e16"
      },
      "outputs": [],
      "source": [
        "resultsDf_a.sort_values(by=['Test RMSE'],ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fd609d",
      "metadata": {
        "id": "e7fd609d"
      },
      "outputs": [],
      "source": [
        "## Plotting on both the Training and Test data\n",
        "\n",
        "plt.figure(figsize=(18,9))\n",
        "plt.plot(SES_train['Sparkling'], label='Train')\n",
        "plt.plot(SES_test['Sparkling'], label='Test')\n",
        "\n",
        "plt.plot(SES_test['predict'], label='Alpha = 0.05 Simple Exponential Smoothing predictions on Test Set')\n",
        "\n",
        "plt.plot(SES_test['predict', 0.3], label='Alpha = 0.3 Simple Exponential Smoothing predictions on Test Set')\n",
        "\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16e0e5f",
      "metadata": {
        "scrolled": true,
        "id": "a16e0e5f"
      },
      "outputs": [],
      "source": [
        "resultsDf_2 = pd.DataFrame({'Test RMSE': [resultsDf_a.sort_values(by=['Test RMSE'],ascending=True).values[0][2]]}\n",
        "                           ,index=['_____'])  # Complete the code to check the perfromance of the 'Alpha=0.3,SimpleExponentialSmoothing' \n",
        "\n",
        "\n",
        "resultsDf = pd.concat([resultsDf, resultsDf_2])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Double Exponential Smoothing (Holt's Model)"
      ],
      "metadata": {
        "id": "uYlnHXuTfwGr"
      },
      "id": "uYlnHXuTfwGr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two parameters  𝛼  and  𝛽  are estimated in this model. Level and Trend are accounted for in this model."
      ],
      "metadata": {
        "id": "fuK95aiqzS4D"
      },
      "id": "fuK95aiqzS4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "135ee8c0",
      "metadata": {
        "id": "135ee8c0"
      },
      "outputs": [],
      "source": [
        "DES_train = '_____'.copy() # Complete the code to create a copy of the train dataset\n",
        "DES_test = '_____'.copy() # Complete the code to create a copy of the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85470dd",
      "metadata": {
        "id": "b85470dd"
      },
      "outputs": [],
      "source": [
        "model_DES =  Holt(DES_train['Sparkling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208cb93d",
      "metadata": {
        "id": "208cb93d"
      },
      "outputs": [],
      "source": [
        "model_DES_autofit = model_DES.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b12ff4",
      "metadata": {
        "id": "53b12ff4"
      },
      "outputs": [],
      "source": [
        "model_DES_autofit.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4648bd",
      "metadata": {
        "id": "1f4648bd"
      },
      "outputs": [],
      "source": [
        "DES_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9bf6bc2",
      "metadata": {
        "id": "e9bf6bc2"
      },
      "outputs": [],
      "source": [
        "## Prediction on the test data\n",
        "\n",
        "DES_test['auto_predict'] = model_DES_autofit.forecast(steps=55)\n",
        "DES_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "847b0ac8",
      "metadata": {
        "id": "847b0ac8"
      },
      "outputs": [],
      "source": [
        "## Plotting on both the Training and Test using autofit\n",
        "\n",
        "plt.figure(figsize=(18,9))\n",
        "plt.plot(DES_train['Sparkling'], label='Train')\n",
        "plt.plot(DES_test['Sparkling'], label='Test')\n",
        "\n",
        "plt.plot(DES_test['auto_predict'], label='Alpha = 0.688,Beta = 9.99e-05,DoubleExponentialSmoothing predictions on Test Set')\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9e51a0",
      "metadata": {
        "id": "4c9e51a0"
      },
      "outputs": [],
      "source": [
        "## Test Data\n",
        "\n",
        "rmse_model_test = metrics.mean_squared_error(DES_test['Sparkling'],DES_test['auto_predict'],squared=False)\n",
        "print(\"For Alpha=0.688,Beta=0.00009,DoubleExponentialSmoothing predictions on Test Data,  RMSE is %3.3f\" %(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a16290",
      "metadata": {
        "id": "66a16290"
      },
      "outputs": [],
      "source": [
        "resultsDf_DES = pd.DataFrame({'Test RMSE': [rmse_model_test]}\n",
        "                           ,index=['______'])  # Complete the code to check the perfromance of the 'Alpha=0.688,Beta=0.00009,DoubleExponentialSmoothing' \n",
        "\n",
        "resultsDf = pd.concat([resultsDf, resultsDf_DES])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfdf66f",
      "metadata": {
        "id": "dbfdf66f"
      },
      "outputs": [],
      "source": [
        "## First we will define an empty dataframe to store our values from the loop\n",
        "\n",
        "resultsDf_b = pd.DataFrame({'Alpha Values':[],'Beta Values':[],'Train RMSE':[],'Test RMSE': []})\n",
        "resultsDf_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6420e4e",
      "metadata": {
        "id": "e6420e4e"
      },
      "outputs": [],
      "source": [
        "len(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9592a2",
      "metadata": {
        "id": "6b9592a2"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(0.3,1.1,0.1):\n",
        "    for j in np.arange(0.3,1.1,0.1):\n",
        "        model_DES_alpha_i_j = model_DES.fit(smoothing_level=i,smoothing_trend=j,optimized=False,use_brute=True)\n",
        "        DES_train['predict',i,j] = model_DES_alpha_i_j.fittedvalues\n",
        "        DES_test['predict',i,j] = model_DES_alpha_i_j.forecast(steps=55)\n",
        "        \n",
        "        rmse_model_train = metrics.mean_squared_error(DES_train['Sparkling'],DES_train['predict',i,j],squared=False)\n",
        "        \n",
        "        rmse_model_test = metrics.mean_squared_error(DES_test['Sparkling'],DES_test['predict',i,j],squared=False)\n",
        "        \n",
        "        resultsDf_b = resultsDf_b.append({'Alpha Values':i,'Beta Values':j,'Train RMSE':rmse_model_train\n",
        "                                          ,'Test RMSE':rmse_model_test}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1be6ce5",
      "metadata": {
        "id": "b1be6ce5"
      },
      "outputs": [],
      "source": [
        "resultsDf_b.sort_values(by=['Test RMSE']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8675124f",
      "metadata": {
        "id": "8675124f"
      },
      "outputs": [],
      "source": [
        "DES_test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4afb007",
      "metadata": {
        "id": "e4afb007"
      },
      "outputs": [],
      "source": [
        "resultsDf_3 = pd.DataFrame({'Test RMSE': [resultsDf_b.sort_values(by=['Test RMSE']).values[0][3]]}\n",
        "                           ,index=['Alpha=0.6,Beta=0.00010,DoubleExponentialSmoothing'])   # Complete the code to check the perfromance of the 'Alpha=0.6,Beta=0.00010,DoubleExponentialSmoothing' \n",
        "\n",
        "resultsDf = pd.concat([resultsDf, resultsDf_3])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triple Exponential Smoothing (Holt - Winter's Model)"
      ],
      "metadata": {
        "id": "ORxq1EPaf3rf"
      },
      "id": "ORxq1EPaf3rf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three parameters  𝛼 ,  𝛽  and  𝛾  are estimated in this model. Level, Trend and Seasonality are accounted for in this model."
      ],
      "metadata": {
        "id": "S3hoIg_8xsIi"
      },
      "id": "S3hoIg_8xsIi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bae625f",
      "metadata": {
        "id": "3bae625f"
      },
      "outputs": [],
      "source": [
        "# Creating the copy of train and test dataset \n",
        "TES_train = '_____'.copy() # Complete the code to create a copy of the train dataset\n",
        "TES_test = '_____'.copy() # Complete the code to create a copy of the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042efd53",
      "metadata": {
        "id": "042efd53"
      },
      "outputs": [],
      "source": [
        "model_TES = ExponentialSmoothing(TES_train['Sparkling'],trend='additive',seasonal='multiplicative',freq='M')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a216d579",
      "metadata": {
        "id": "a216d579"
      },
      "outputs": [],
      "source": [
        "model_TES_autofit = model_TES.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8afd6eb2",
      "metadata": {
        "id": "8afd6eb2"
      },
      "outputs": [],
      "source": [
        "model_TES_autofit.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535ae13b",
      "metadata": {
        "id": "535ae13b"
      },
      "outputs": [],
      "source": [
        "##PREDICTION ON TEST SET\n",
        "TES_test['auto_predict'] = model_TES_autofit.forecast(steps=len(df_test))\n",
        "TES_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a48212c",
      "metadata": {
        "id": "8a48212c"
      },
      "outputs": [],
      "source": [
        "## Plotting on both the Training and Test using autofit\n",
        "\n",
        "plt.figure(figsize=(18,9))\n",
        "plt.plot(TES_train['Sparkling'], label='Train')\n",
        "plt.plot(TES_test['Sparkling'], label='Test')\n",
        "\n",
        "plt.plot(TES_test['auto_predict'], label='Alpha=0.111,Beta=0.061,Gamma=0.395,TripleExponentialSmoothing predictions on Test Set')\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99aa92ba",
      "metadata": {
        "id": "99aa92ba"
      },
      "outputs": [],
      "source": [
        "## Test Data\n",
        "\n",
        "rmse_model_test = metrics.mean_squared_error(TES_test['Sparkling'],TES_test['auto_predict'],squared=False)\n",
        "print(\"Alpha=0.111,Beta=0.061,Gamma=0.395,TripleExponentialSmoothing predictions on Test Set,  RMSE is %3.3f\" %(rmse_model_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c01572f",
      "metadata": {
        "id": "3c01572f"
      },
      "outputs": [],
      "source": [
        "## First we will define an empty dataframe to store our values from the loop\n",
        "resultsDf_c = pd.DataFrame({'Alpha Values':[],'Beta Values':[],'Gamma Values':[],'Train RMSE':[],'Test RMSE': []})\n",
        "resultsDf_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6171e067",
      "metadata": {
        "id": "6171e067"
      },
      "outputs": [],
      "source": [
        "for i in np.arange(0.3,1.1,0.1):\n",
        "    for j in np.arange(0.3,1.1,0.1):\n",
        "        for k in np.arange(0.3,1.1,0.1):\n",
        "            model_TES_alpha_i_j_k = model_TES.fit(smoothing_level=i,smoothing_trend=j,smoothing_seasonal=k,optimized=False,use_brute=True)\n",
        "            TES_train['predict',i,j,k] = model_TES_alpha_i_j_k.fittedvalues\n",
        "            TES_test['predict',i,j,k] = model_TES_alpha_i_j_k.forecast(steps=55)\n",
        "        \n",
        "            rmse_model_train = metrics.mean_squared_error(TES_train['Sparkling'],TES_train['predict',i,j,k],squared=False)\n",
        "            \n",
        "            rmse_model_test = metrics.mean_squared_error(TES_test['Sparkling'],TES_test['predict',i,j,k],squared=False)\n",
        "            \n",
        "            resultsDf_c = resultsDf_c.append({'Alpha Values':i,'Beta Values':j,'Gamma Values':k,\n",
        "                                                  'Train RMSE':rmse_model_train,'Test RMSE':rmse_model_test}\n",
        "                                                 , ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd32e70",
      "metadata": {
        "id": "bdd32e70"
      },
      "outputs": [],
      "source": [
        "resultsDf_c.sort_values(by=['Test RMSE']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb437c70",
      "metadata": {
        "id": "fb437c70"
      },
      "outputs": [],
      "source": [
        "## Plotting on both the Training and Test data using brute force alpha, beta and gamma determination\n",
        "\n",
        "plt.figure(figsize=(18,9))\n",
        "plt.plot(TES_train['Sparkling'], label='Train')\n",
        "plt.plot(TES_test['Sparkling'], label='Test')\n",
        "\n",
        "#The value of alpha and beta is taken like that by python\n",
        "plt.plot(TES_test['predict', 0.3, 0.3, 0.3], label='Alpha=0.3,Beta=0.3,Gamma=0.3,TripleExponentialSmoothing predictions on Test Set')\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd9dd9b",
      "metadata": {
        "id": "cbd9dd9b"
      },
      "outputs": [],
      "source": [
        "resultsDf_2 = pd.DataFrame({'Test RMSE': [resultsDf_c.sort_values(by=['Test RMSE']).values[0][4]]}\n",
        "                           ,index=['Alpha= 0.3,Beta=0.3,Gamma=0.3,TripleExponentialSmoothing'])  # Complete the code to check the perfromance of the 'Alpha= 0.3,Beta=0.3,Gamma=0.3,TripleExponentialSmoothing' \n",
        "\n",
        "\n",
        "resultsDf = pd.concat([resultsDf, resultsDf_2])\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsDf1 = resultsDf.sort_values(by=['Test RMSE'])\n",
        "resultsDf1"
      ],
      "metadata": {
        "id": "keK_J9f0BceM"
      },
      "id": "keK_J9f0BceM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for Stationarity "
      ],
      "metadata": {
        "id": "ICXk2CEof-D0"
      },
      "id": "ICXk2CEof-D0"
    },
    {
      "cell_type": "markdown",
      "id": "00a8b493",
      "metadata": {
        "id": "00a8b493"
      },
      "source": [
        "Let's check for the stationarity of the data on which the model is being built on using appropriate statistical tests and also mention the hypothesis for the statistical test. If the data is found to be non-stationary, take appropriate steps to make it stationary. Check the new data for stationarity and comment. Note: Stationarity should be checked at alpha = 0.05."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40442ed",
      "metadata": {
        "id": "e40442ed"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "def test_stationarity(timeseries):\n",
        "    \n",
        "    #determining roll statistics\n",
        "    rolmean = timeseries.rolling(window=12).mean()\n",
        "    rolstd = timeseries.rolling(window=12).std()\n",
        "    \n",
        "    ##plot rolling Statistics:\n",
        "    orig = plt.plot(timeseries,color='blue',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean and Standard Deviation')\n",
        "    plt.show(block=False)\n",
        "    \n",
        "    #Perform Dickey-Fuller Test:\n",
        "    print('Results of Dickey Fuller Test:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print(dfoutput,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0bd7c03",
      "metadata": {
        "id": "a0bd7c03"
      },
      "outputs": [],
      "source": [
        "test_stationarity(df_train['Sparkling'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834467e4",
      "metadata": {
        "id": "834467e4"
      },
      "source": [
        "**Write the Observations**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c755c0e",
      "metadata": {
        "id": "1c755c0e"
      },
      "source": [
        "H0 : The series is not stationary \n",
        "\n",
        "Ha: The series is Stationary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a24ec752",
      "metadata": {
        "id": "a24ec752"
      },
      "source": [
        "- autolag{“AIC”, “BIC”, “t-stat”, None}\n",
        "Method to use when automatically determining the lag length among the values 0, 1, …, maxlag.\n",
        "\n",
        "- If “AIC” (default) or “BIC”, then the number of lags is chosen to minimize the corresponding information criterion.\n",
        "\n",
        "- “t-stat” based choice of maxlag. Starts with maxlag and drops a lag until the t-statistic on the last lag length is significant using a 5%-sized test.\n",
        "\n",
        "- If None, then the number of included lags is set to maxlag.\n",
        "\n",
        "\n",
        "- The null hypothesis of the Augmented Dickey-Fuller is that there is a unit root, with the alternative that there is no unit root. If the pvalue is above a critical size, then we cannot reject that there is a unit root."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86865e6f",
      "metadata": {
        "id": "86865e6f"
      },
      "source": [
        "Stationary TS allow us to essentially have copies of things which enables us to build appropriate statistical models for forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LETS BUILD IT ON DF_TRAIN MODEL"
      ],
      "metadata": {
        "id": "Qxu9C2e7siP9"
      },
      "id": "Qxu9C2e7siP9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d292cc12",
      "metadata": {
        "id": "d292cc12"
      },
      "outputs": [],
      "source": [
        "dftest = adfuller(df_train.diff().dropna(),regression='ct')\n",
        "print('DF test statistics is %3.3f' %dftest[0])\n",
        "print('DF test p-value is', dftest[1])\n",
        "print('DF test p-value is', dftest[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b3f59f",
      "metadata": {
        "scrolled": true,
        "id": "f3b3f59f"
      },
      "outputs": [],
      "source": [
        "df_train.plot(grid=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automated ARIMA Model based on lowest AIC"
      ],
      "metadata": {
        "id": "INbxjvW5gJNi"
      },
      "id": "INbxjvW5gJNi"
    },
    {
      "cell_type": "markdown",
      "id": "6683ec58",
      "metadata": {
        "id": "6683ec58"
      },
      "source": [
        "Let's build an automated version of the ARIMA model in which the parameters are selected using the lowest Akaike Information Criteria (AIC) on the training data and evaluate this model on the test data using RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac71b031",
      "metadata": {
        "id": "ac71b031"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "p = q = range(0,4)\n",
        "d = range(1,2)\n",
        "pdq = list(itertools.product(p,d,q))\n",
        "print('Examples of the parameter combinations for the models')\n",
        "for i in range(0,len(pdq)):\n",
        "    print('Model : {}'.format(pdq[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc035dce",
      "metadata": {
        "id": "cc035dce"
      },
      "outputs": [],
      "source": [
        "# Creating an empty Dataframe with column names only\n",
        "ARIMA_AIC = pd.DataFrame(columns=['param', 'AIC'])\n",
        "ARIMA_AIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08a9414",
      "metadata": {
        "id": "c08a9414"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "for param in pdq: # running a loop within the pdq parameters defined by itertools\n",
        "    ARIMA_model  =  ARIMA(df_train['Sparkling'].values, order=param).fit()\n",
        "    print('ARIMA{} - AIC{}'.format(param, ARIMA_model.aic))\n",
        "    \n",
        "    #printing the parameters and the AIC from the fitted models\n",
        "    ARIMA_AIC = ARIMA_AIC.append({'param': param, 'AIC': ARIMA_model.aic},ignore_index=True)\n",
        "    \n",
        "    #appending the AIC values and the model parameters to the previously created data frame\n",
        "    #for easier understanding and sorting of the AIC values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21994dd8",
      "metadata": {
        "id": "21994dd8"
      },
      "outputs": [],
      "source": [
        "ARIMA_AIC.sort_values(by='AIC',ascending=True).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61d21cdb",
      "metadata": {
        "id": "61d21cdb"
      },
      "outputs": [],
      "source": [
        "auto_ARIMA = ARIMA(df_train, order=(2,1,2))\n",
        "\n",
        "results_auto_ARIMA = auto_ARIMA.fit()\n",
        "\n",
        "print(results_auto_ARIMA.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f332e7",
      "metadata": {
        "id": "d4f332e7"
      },
      "outputs": [],
      "source": [
        "results_auto_ARIMA.plot_diagnostics();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on the Test Set using this model and evaluate the model."
      ],
      "metadata": {
        "id": "DWGoQ_GR3Me6"
      },
      "id": "DWGoQ_GR3Me6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "118a1233",
      "metadata": {
        "id": "118a1233"
      },
      "outputs": [],
      "source": [
        "predicted_auto_ARIMA = results_auto_ARIMA.forecast(steps=len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ab2d9a",
      "metadata": {
        "id": "e1ab2d9a"
      },
      "outputs": [],
      "source": [
        "## Mean Absolute Percentage Error (MAPE) - Function Definition\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean((np.abs(y_true-y_pred))/(y_true))*100\n",
        "\n",
        "## Importing the mean_squared_error function from sklearn to calculate the RMSE\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ec02592",
      "metadata": {
        "id": "5ec02592"
      },
      "outputs": [],
      "source": [
        "rmse = mean_squared_error(df_test['Sparkling'],predicted_auto_ARIMA,squared=False)\n",
        "mape = mean_absolute_percentage_error(df_test['Sparkling'],predicted_auto_ARIMA)\n",
        "print('RMSE:',rmse,'\\nMAPE:',mape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94425feb",
      "metadata": {
        "id": "94425feb"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from sklearn.metrics import  mean_squared_error\n",
        "rmse = sqrt(mean_squared_error(df_test.Sparkling,predicted_auto_ARIMA))\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40b5b00",
      "metadata": {
        "id": "e40b5b00"
      },
      "outputs": [],
      "source": [
        "resultsDf = pd.DataFrame({'RMSE': rmse,'MAPE':mape}\n",
        "                           ,index=['ARIMA(2,1,2)'])\n",
        "\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52fbf5ba",
      "metadata": {
        "id": "52fbf5ba"
      },
      "source": [
        "### Automated SARIMA Model based on lowest AIC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build an automated version of the SARIMA model in which the parameters are selected using the lowest Akaike Information Criteria (AIC) on the training data and evaluate this model on the test data using RMSE."
      ],
      "metadata": {
        "id": "O4eq3xi4JNo1"
      },
      "id": "O4eq3xi4JNo1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f4a109",
      "metadata": {
        "id": "15f4a109"
      },
      "outputs": [],
      "source": [
        "plot_acf(df_train.diff(),title='Training Data Autocorrelation',missing='drop',lags=40);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8f9e9b",
      "metadata": {
        "id": "7c8f9e9b"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "p = q = range(0, 4)\n",
        "d= range(1,2)\n",
        "D = range(0,1)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "PDQ = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, D, q))]\n",
        "print('Examples of the parameter combinations for the Model are')\n",
        "for i in range(1,len(pdq)):\n",
        "    print('Model: {}{}'.format(pdq[i], PDQ[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cafaff5",
      "metadata": {
        "id": "7cafaff5"
      },
      "outputs": [],
      "source": [
        "SARIMA_AIC = pd.DataFrame(columns=['param','seasonal', 'AIC'])\n",
        "SARIMA_AIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "919f7e81",
      "metadata": {
        "id": "919f7e81"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "for param in pdq:\n",
        "    for param_seasonal in PDQ:\n",
        "        SARIMA_model = sm.tsa.statespace.SARIMAX(df_train['Sparkling'].values,\n",
        "                                            order=param,\n",
        "                                            seasonal_order=param_seasonal,\n",
        "                                            enforce_stationarity=False,\n",
        "                                            enforce_invertibility=False)\n",
        "            \n",
        "        results_SARIMA = SARIMA_model.fit(maxiter=1000)\n",
        "        print('SARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results_SARIMA.aic))\n",
        "        SARIMA_AIC = SARIMA_AIC.append({'param':param,'seasonal':param_seasonal ,'AIC': results_SARIMA.aic}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27551df8",
      "metadata": {
        "id": "27551df8"
      },
      "outputs": [],
      "source": [
        "SARIMA_AIC.sort_values(by='AIC',ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b1d002",
      "metadata": {
        "id": "21b1d002"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "auto_SARIMA = sm.tsa.statespace.SARIMAX(df_train['Sparkling'],order=(3,1,2),seasonal_order=(1,0,3,12),enforce_stationarity=False,\n",
        "                                       enforce_invertibility=False)\n",
        "results_auto_SARIMA = auto_SARIMA.fit(maxiter=1000)\n",
        "print(results_auto_SARIMA.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06358da3",
      "metadata": {
        "id": "06358da3"
      },
      "outputs": [],
      "source": [
        "results_auto_SARIMA.plot_diagnostics();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f9a383",
      "metadata": {
        "id": "a8f9a383"
      },
      "outputs": [],
      "source": [
        "#Predict on the Test Set using this model and evaluate the model.\n",
        "predicted_auto_SARIMA = results_auto_SARIMA.get_forecast(steps=len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3a9dca",
      "metadata": {
        "id": "cf3a9dca"
      },
      "outputs": [],
      "source": [
        "predicted_auto_SARIMA.summary_frame(alpha=0.05).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714cdd7d",
      "metadata": {
        "id": "714cdd7d"
      },
      "outputs": [],
      "source": [
        "rmse = mean_squared_error(df_test['Sparkling'],predicted_auto_SARIMA.predicted_mean,squared=False)\n",
        "mape = mean_absolute_percentage_error(df_test['Sparkling'],predicted_auto_SARIMA.predicted_mean)\n",
        "print('RMSE:',rmse,'\\nMAPE:',mape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe8d6d0b",
      "metadata": {
        "id": "fe8d6d0b"
      },
      "outputs": [],
      "source": [
        "temp_resultsDf = pd.DataFrame({'RMSE': rmse,'MAPE':mape}\n",
        "                           ,index=['SARIMA(2,1,3)(1,0,3,12)'])\n",
        "\n",
        "\n",
        "resultsDf = pd.concat([resultsDf,temp_resultsDf])\n",
        "\n",
        "resultsDf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsDf2 = pd.concat([resultsDf,temp_resultsDf])\n",
        "resultsDf2"
      ],
      "metadata": {
        "id": "9Grgp8FgBlL9"
      },
      "id": "9Grgp8FgBlL9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsDf3 = resultsDf2[['RMSE']]\n",
        "resultsDf3.rename(columns = { 'RMSE' : 'Test RMSE'}, inplace = True)\n",
        "resultsDf30"
      ],
      "metadata": {
        "id": "a5uDkxoCBohA"
      },
      "id": "a5uDkxoCBohA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison and Final Model Selection"
      ],
      "metadata": {
        "id": "NXYC3hDkss5u"
      },
      "id": "NXYC3hDkss5u"
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_model_table = pd.concat([resultsDf1, resultsDf3])\n",
        "comparison_model_table.sort_values(by = 'Test RMSE')"
      ],
      "metadata": {
        "id": "0t3OLLuYBPzF"
      },
      "id": "0t3OLLuYBPzF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forecasting using Final Model"
      ],
      "metadata": {
        "id": "33jFxT-k63uz"
      },
      "id": "33jFxT-k63uz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the model-building exercise, let's build the most optimum model(s) on the complete data and predict 12 months into the future with appropriate confidence intervals/bands"
      ],
      "metadata": {
        "id": "TTmX2zVCqh3_"
      },
      "id": "TTmX2zVCqh3_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e846be35",
      "metadata": {
        "id": "e846be35"
      },
      "outputs": [],
      "source": [
        "model = ExponentialSmoothing(df['Sparkling'],trend='additive',seasonal='multiplicative',freq='M')\n",
        "# fit model\n",
        "model_fit = model.fit(smoothing_level=0.3,smoothing_trend=0.3,smoothing_seasonal=0.3,optimized=False,use_brute=True)\n",
        "# make prediction\n",
        "yhat = model_fit.predict(start='31-08-1995',end='31-08-1996')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30366700",
      "metadata": {
        "id": "30366700"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,9))\n",
        "plt.plot(df['Sparkling'], label='Actual Dataset')\n",
        "\n",
        "\n",
        "plt.plot(yhat,label='Alpha = Beta = Gamma = 0.3, Triple Exponential Smoothing Model')\n",
        "\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the below code, we have calculated the upper and lower confidence bands at 95% confidence level\n",
        "- Here we are taking the multiplier to be 1.96 as we want to plot with respect to a 95% confidence intervals."
      ],
      "metadata": {
        "id": "FPknqW5E6--V"
      },
      "id": "FPknqW5E6--V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be333cc",
      "metadata": {
        "id": "3be333cc"
      },
      "outputs": [],
      "source": [
        "pred_1_df = pd.DataFrame({'lower_CI':yhat - 1.96*np.std(model_fit.resid,ddof=1),\n",
        "                          'prediction':yhat,\n",
        "                          'upper_ci':yhat + 1.96*np.std(model_fit.resid,ddof=1)})\n",
        "pred_1_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044dfc8d",
      "metadata": {
        "id": "044dfc8d"
      },
      "outputs": [],
      "source": [
        "pred_1_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df72801",
      "metadata": {
        "id": "6df72801"
      },
      "outputs": [],
      "source": [
        "# plot the forecast along with the confidence band\n",
        "\n",
        "axis = df.plot(label='Actual', figsize=(15,8))\n",
        "pred_1_df['prediction'].plot(ax=axis, label='Forecast', alpha=0.5)\n",
        "axis.fill_between(pred_1_df.index, pred_1_df['lower_CI'], pred_1_df['upper_ci'], color='k', alpha=.15)\n",
        "axis.set_xlabel('Year-Months')\n",
        "axis.set_ylabel('Sales')\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Business Insights and Recommendations"
      ],
      "metadata": {
        "id": "CksY1LeV1Bci"
      },
      "id": "CksY1LeV1Bci"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- \n"
      ],
      "metadata": {
        "id": "6Ny1k3CoPK7Q"
      },
      "id": "6Ny1k3CoPK7Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "__________"
      ],
      "metadata": {
        "id": "PwGHwc1OH3gV"
      },
      "id": "PwGHwc1OH3gV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W_Ho8VGKDu3S",
        "9d5QE-n57qf9",
        "xxhpZv9y-qTw",
        "_ruS1OQwB_fX",
        "5TcqcxbK-qT3",
        "GUSrEdHZqHbl",
        "xNr4bWoM-qT5",
        "kUJ_B5KxhU3D",
        "HdlR3wVEMyfW",
        "DfHslI2IMcAo",
        "v8bdGtOaqYtW",
        "L8hu0DaYWNoC",
        "lCBmm5L-rA0o",
        "P2TcixowVlSL",
        "but7oI7m2vvY",
        "hsnaQaXxXVNC",
        "p8L4YPHcXdzh",
        "BORpLf603HRr",
        "FnwnQeVMYJjY",
        "_P3Jx09Ucg1x",
        "D42POulbfTks",
        "x7vtp9Jdfk0A",
        "H_3ju6TfxaXn",
        "7c30bad7",
        "uYlnHXuTfwGr",
        "ORxq1EPaf3rf",
        "ICXk2CEof-D0",
        "INbxjvW5gJNi",
        "52fbf5ba",
        "NXYC3hDkss5u",
        "33jFxT-k63uz",
        "CksY1LeV1Bci"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}